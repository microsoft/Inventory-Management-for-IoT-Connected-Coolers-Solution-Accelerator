{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Ingest IoT Data\n",
        "---\n",
        "The connected cooler sends data regarding products removed from monitored coolers hourly per cooler. This data is recieved by IoTHub and then transformed and recorded in \n",
        "the IoTInventoryAction table.  This notebook can be run on a user defined cadance (through [Synapse pipelines](https://docs.microsoft.com/en-us/azure/synapse-analytics/get-started-pipelines) for example) to update the rest of the inventory model with \n",
        "this incoming IoT data from the cooler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 1.0 Get IoT data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 1.1 Imports and configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import *\n",
        "from notebookutils import mssparkutils\n",
        "import json\n",
        "sc = spark.sparkContext\n",
        "\n",
        "synapse_account_name = 'connected-cooler-sa-synapsews'\n",
        "data_lake_account_name = '<data_lake_account_name>' # Synapse Workspace ADLS\n",
        "file_system_name = 'connectedcoolersasynfs'\n",
        "synapse_workspace_name = '<synapse_workspace_name>'\n",
        "database_name = 'ContosoCoolerDatabase'\n",
        "\n",
        "spark.conf.set(\"spark.storage.synapse.linkedServiceName\", f\"{synapse_account_name}-WorkspaceDefaultStorage\")\n",
        "spark.conf.set(\"fs.azure.account.oauth.provider.type\", \"com.microsoft.azure.synapse.tokenlibrary.LinkedServiceBasedTokenProvider\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 1.2 Read in data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "picklist_df = spark.read.parquet(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/picklist')\n",
        "picklistitem_df = spark.read.parquet(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/picklistitem')\n",
        "iotinventoryaction_df = spark.sql(f\"SELECT * FROM `{database_name}`.`iotinventoryaction`\")\n",
        "#iotinventoryaction_df = spark.read.option('header', 'true').csv(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/iotinventoryaction3/*.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2.0 Create Picklists from IoT data\n",
        "- This tasks takes the latest data incoming to the IoTInventoryAction table (from the connected Coolers) and creates inventory PickLists.  These picklists will \n",
        "be processed to adjust the coolers ballance on hand of the particluar item using code from the inventory_functions notebook.  This code should also be scheduled \n",
        "to run in a pipeline to make these adjustments periodically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 2.1 Get last picklist id and timesstamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "w = Window.orderBy(desc('PickListId'))\n",
        "last_picklistdata = picklist_df.withColumn('Rank',dense_rank().over(w)).head()\n",
        "\n",
        "print(f\"id: {last_picklistdata['PickListId']}, ts: {last_picklistdata['PickListFulfilledTimestamp']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 2.2 Get all iot messages after last load date "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "iotinventoryaction_update_df = iotinventoryaction_df.filter(to_timestamp('PickTime') > to_timestamp(lit(last_picklistdata['PickListFulfilledTimestamp'])))\n",
        "display(iotinventoryaction_update_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 2.3 Add index column incrementing from last value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "iotinventoryaction_update_df2 = iotinventoryaction_update_df \\\n",
        "    .select(row_number() \\\n",
        "    .over(Window.partitionBy() \\\n",
        "    .orderBy(iotinventoryaction_update_df['PickTime'])) \\\n",
        "    .alias(\"PickListId\"),\"PickTime\",\"CoolerId\",\"ItemSku\", \"Quantity\")\n",
        "\n",
        "iotinventoryaction_update_df3 = iotinventoryaction_update_df2 \\\n",
        "    .withColumn('PickListId', col('PickListId') + last_picklistdata['PickListId']) \\\n",
        "    .withColumn('CoolerId', col('CoolerId') \\\n",
        "    .cast(IntegerType()))\n",
        "\n",
        "iotinventoryaction_update_df3.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 2.4 Write iot messages to PickList and PickListItem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "iotinventoryaction_update_df3 \\\n",
        "    .select('PickListId', col('PickTime') \\\n",
        "    .alias('PickListFufilledTimestamp'), 'CoolerId') \\\n",
        "    .write.insertInto(f\"{database_name}.picklist\")\n",
        "\n",
        "iotinventoryaction_update_df3 \\\n",
        "    .select('PickListId','ItemSku',col('Quantity') \\\n",
        "    .alias('ItemQuantity')) \\\n",
        "    .write.insertInto(f\"{database_name}.picklistItem\")"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
