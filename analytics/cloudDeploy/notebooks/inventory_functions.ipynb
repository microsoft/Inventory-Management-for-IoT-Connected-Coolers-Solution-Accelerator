{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License.\n",
        "\n",
        "# Inventory Functions\n",
        "---\n",
        "There are two functions contained in this notebook. Adjusting the CoolerItemBalance table to update the product inventory based on what picklists are processed, \n",
        "and code to generate a projected restock date for each cooler based on the Many Models Machine Learning prediction of future demand based on data collected from \n",
        "the IoT system (see the demand_forecasting notebook and related documentation). As with all of these notebooks, this is desined to be run on an appropriate cadance \n",
        "for example using [Synapse pipelines](https://docs.microsoft.com/en-us/azure/synapse-analytics/get-started-pipelines) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Adjusting the CoolerItemBalance table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 1.0 Imports and initalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### 1.1 Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import *\n",
        "from notebookutils import mssparkutils\n",
        "import json\n",
        "sc = spark.sparkContext\n",
        "\n",
        "synapse_account_name = '<Name of your Synapse Account>'\n",
        "data_lake_account_name = '<Data Lake Account Name>' # Synapse Workspace ADLS\n",
        "file_system_name = '<Data Lake Container Name>'\n",
        "database_name = '<Database Name>'\n",
        "\n",
        "spark.conf.set(\"spark.storage.synapse.linkedServiceName\", f\"{synapse_account_name}-WorkspaceDefaultStorage\")\n",
        "spark.conf.set(\"fs.azure.account.oauth.provider.type\", \"com.microsoft.azure.synapse.tokenlibrary.LinkedServiceBasedTokenProvider\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### 1.1 Get data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "cooler_df = spark.read.parquet(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/cooler')\n",
        "cooler_ids = [wh[0] for wh in cooler_df.select('CoolerId').collect()]\n",
        "picklist_df = spark.read.parquet(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/picklist')\n",
        "picklistitem_df = spark.read.parquet(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/picklistitem')\n",
        "iotinventoryaction_df = spark.read.parquet(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/iotinventoryaction')\n",
        "inventoryprojected_df = spark.read.parquet(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/inventoryprojected')\n",
        "cooleritembalance_df = spark.read.parquet(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/cooleritembalance')\n",
        "item_df = spark.read.parquet(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/item')\n",
        "restockprojected_df = spark.read.parquet(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/{database_name}/restockprojected')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 2.0 Adjust CoolerItemBalance table\n",
        "- This tasks takes the latest items from the PickList data and updates the CoolerItemBalance table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### 2.1 Get last update date for each sku"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "w = Window.partitionBy('CoolerId','ItemSku').orderBy(desc('Timestamp'))\n",
        "df = cooleritembalance_df.withColumn('Rank',dense_rank().over(w))\n",
        "\n",
        "last_item_balance_df = df.filter(df.Rank == 1).drop(df.Rank).orderBy('CoolerId','ItemSku')\n",
        "last_item_balance_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### 2.2 Get overall last update from CoolerItemBalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#last_update = last_item_balance_df.select('Timestamp').orderBy(desc('Timestamp')).head()[0]\n",
        "\n",
        "w = Window.orderBy(desc('Timestamp'))\n",
        "df = last_item_balance_df.withColumn('Rank',dense_rank().over(w))\n",
        "\n",
        "last_update = df.filter(df.Rank == 1).drop(df.Rank).select('Timestamp')[0]\n",
        "print(last_update)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### 2.3 Get the sum of items for the period between last item input into CoolerItemBalance and current"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "items_removed_df = picklist_df.join(picklistitem_df, 'PickListId')\n",
        "\n",
        "items_since_update_df = items_removed_df.filter(f\"PickListFulfilledTimestamp > timestamp'{last_update}'\")\n",
        "\n",
        "items_current_sum = items_since_update_df.groupBy('CoolerId', 'ItemSku').agg(sum('ItemQuantity').alias('SumQuantity'),max('PickListFulfilledTimestamp').alias('PickListFulfilledTimestamp'))\n",
        "items_current_sum.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### 2.4 Write update back to CoolerItemBalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# write update back to CoolerItemBalance\n",
        "wib_entry_df = items_current_sum.join(last_item_balance_df.alias(\"b\"), \n",
        "    (items_current_sum.CoolerId == last_item_balance_df.CoolerId) & (items_current_sum.ItemSku == last_item_balance_df.ItemSku)).withColumn(\n",
        "        'ActualItemQuantity',\n",
        "        last_item_balance_df.ActualItemQuantity - items_current_sum.SumQuantity).select(\"b.CoolerId\",\"b.ItemSku\",col('PickListFulfilledTimestamp').alias('Timestamp'),\"ActualItemQuantity\")\n",
        "\n",
        "wib_entry_df.write.insertInto(f\"{database_name}.cooleritembalance\")\n",
        "\n",
        "wib_entry_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Get Projected Restock Dates\n",
        "-  Get latest ActualItemQuantity and TS from CoolerItemBalance\n",
        "- Join present with projected from RestockProjected after this TS\n",
        "- Loop decrementing per SKU until MinimumStockQuantity from Item\n",
        "- Move current to previous in RestockProjected\n",
        "- insert new projected in RestockProjected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 1.0 Add cumulative column to inventoryprojected grouping by cooler and sku sorted by timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "cumSum = inventoryprojected_df \\\n",
        "    .withColumn(\"cumulativeSum\", sum(inventoryprojected_df[\"ItemQuantity\"]) \\\n",
        "    .over( Window.partitionBy(\"CoolerId\", \"ItemSku\").orderBy(\"PickListFulfilledTimestamp\")))\n",
        "\n",
        "cumSum.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 2.0 Join cumulative column with CoolerItemBalance and Item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# join cooleritembalance and item on sku\n",
        "# select sku, ActualItemQuantity, and MinimumStockQuantity for each sku\n",
        "# left join with cumSum on Item Sku\n",
        "w = Window.partitionBy('CoolerId','ItemSku').orderBy(desc('Timestamp'))\n",
        "df1 = cooleritembalance_df.join(item_df.alias('b'), 'ItemSku') \\\n",
        "    .withColumn('Rank',dense_rank() \\\n",
        "    .over(w))\n",
        "\n",
        "item_info_df = df1.filter(df1.Rank == 1) \\\n",
        "    .drop(df1.Rank) \\\n",
        "    .orderBy('CoolerId','ItemSku')\\\n",
        "    .select('CoolerId','ItemSku', 'MinimumStockQuantity', 'ActualItemQuantity')\n",
        "\n",
        "df2 = cumSum.join(item_info_df.alias('b'), ((cumSum.CoolerId == item_info_df.CoolerId) & (cumSum.ItemSku == item_info_df.ItemSku))) \\\n",
        "    .select('b.coolerId', 'b.ItemSku', 'PickListFulfilledTimestamp', 'cumulativeSum', 'ActualItemQuantity', 'MinimumStockQuantity')\n",
        "\n",
        "df2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 3.0 Figure out dates for each sku by cooler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "w = Window.partitionBy('CoolerId').orderBy('PickListFulfilledTimestamp')\n",
        "df3 = df2.filter((df2['ActualItemQuantity'] - df2['cumulativeSum']) < df2['MinimumStockQuantity']) \\\n",
        "    .withColumn('Rank',dense_rank() \\\n",
        "    .over(w))\n",
        "\n",
        "df4 = df3.filter(df3.Rank == 1) \\\n",
        "    .drop(df3.Rank).select('CoolerId',col('PickListFulfilledTimestamp') \\\n",
        "    .alias('ProjectedDateTime'), ) \\\n",
        "    .dropDuplicates()\n",
        "\n",
        "df4.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 4.0 Insert into restockprojected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "df5 = df4.alias('a') \\\n",
        "    .join(restockprojected_df.alias('b'), 'CoolerId', 'left') \\\n",
        "    .select('CoolerId','a.ProjectedDateTime', col('b.ProjectedDateTime').alias('PreviousProjectedDateTime'))\n",
        "\n",
        "df5 = df5.withColumn('ProjectedDateTime', to_timestamp('ProjectedDateTime')) \\\n",
        "    .dropDuplicates()\n",
        "    \n",
        "df5.write.insertInto(f\"{database_name}.restockprojected\")\n",
        "    \n",
        "df5.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    }
  ],
  "metadata": {
    "description": null,
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "state": {},
      "version": "0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
