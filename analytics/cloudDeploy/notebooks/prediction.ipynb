{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0c73ec",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation.\n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "# Generate Inventory Predictions\n",
    "---\n",
    "\n",
    "**This notebook is designed to be run from an AzureML Compute instance as outlined in the \n",
    "[Many Models](https://github.com/microsoft/solution-accelerator-many-models/blob/master/EnvironmentSetup.md) documentation**.\n",
    "It allows for the easy submission of an inferencing run on the existing many models pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ec23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore, Dataset\n",
    "import pandas as pd\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# Take a look at Workspace\n",
    "ws.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f868dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_datastore_name = \"automl_many_models2\"\n",
    "container_name = \"mldata\"\n",
    "account_name = \"<Storage Account Name>\"\n",
    "account_key= \"<Storage Account Key>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = Datastore.register_azure_blob_container(\n",
    "    workspace=ws, \n",
    "    datastore_name=blob_datastore_name, \n",
    "    container_name=container_name,\n",
    "    account_name=account_name,\n",
    "    account_key=account_key,\n",
    "    create_if_not_exists=True\n",
    ")\n",
    "\n",
    "ds_predict_path = 'ds-predict'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766e12c",
   "metadata": {},
   "source": [
    "### Generate input file for prediction based on sample data\n",
    "**Note**: the timestamps in this file represent the three weeks after the end of the simulated data. Also note that all item \n",
    "quantities are set to 0.  When finished, the resulting data set will contain a new column with predictions for each row in \n",
    "the time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f08b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus = ['cdc_00', 'crc_90']\n",
    "coolers = [0, 1, 2, 3, 4]\n",
    "hours_rows = 504\n",
    "start_date = '2022-01-01 00:00:00'\n",
    "end_date = '2022-01-21 23:00:00'\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "blob_service_client = BlobServiceClient(f\"https://{account_name}.blob.core.windows.net\",account_key)\n",
    "\n",
    "for cooler in coolers:\n",
    "    for sku in skus:\n",
    "        timestamps = pd.date_range(start=start_date, end=end_date, periods=hours_rows)\n",
    "        list_sku = [sku] * hours_rows\n",
    "        list_cooler = [cooler] * hours_rows\n",
    "        list_quantity = [0] * hours_rows\n",
    "        row_def = {'PickListFulfilledTimestamp':timestamps,'CoolerId': list_cooler,'ItemSku':list_sku, 'ItemQuantity':list_quantity}\n",
    "        df = pd.DataFrame(data=row_def)\n",
    "        df.index.name = 'PickListId'\n",
    "        output = df.to_csv (index=True, encoding = \"utf-8\")\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=f\"{ds_predict_path}/{cooler}-{sku}.csv\")\n",
    "        blob_client.upload_blob(output, blob_type=\"BlockBlob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create file datasets\n",
    "ds_predict = Dataset.File.from_files(path=datastore.path(ds_predict_path), validate=True)\n",
    "\n",
    "# Register the file datasets\n",
    "dataset_name = 'coolerdataset'\n",
    "predict_dataset_name = dataset_name + \"_predict\"\n",
    "ds_predict.register(ws, predict_dataset_name, create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4834cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get a named datastore from the current workspace\n",
    "dstore = Datastore.get(ws, datastore_name='automl_many_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dde99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "# Choose a name for your cluster.\n",
    "amlcompute_cluster_name = \"cpucluster\"\n",
    "\n",
    "found = False\n",
    "# Check if this compute target already exists in the workspace.\n",
    "cts = ws.compute_targets\n",
    "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'AmlCompute':\n",
    "    found = True\n",
    "    print('Found existing compute target.')\n",
    "    compute = cts[amlcompute_cluster_name]\n",
    "    \n",
    "if not found:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D16S_V3',\n",
    "                                                           min_nodes=2,\n",
    "                                                           max_nodes=20)\n",
    "    # Create the cluster.\n",
    "    compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\n",
    "    \n",
    "print('Checking cluster status...')\n",
    "# Can poll for a minimum number of nodes and for a specific timeout.\n",
    "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "compute.wait_for_completion(show_output = True, min_node_count = None, timeout_in_minutes = 20)\n",
    "    \n",
    "# For a more detailed view of current AmlCompute status, use get_status()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc28d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "experiment = Experiment(ws, 'manymodels-prediction-pipeline')\n",
    "\n",
    "filedst_10_models = Dataset.get_by_name(ws, name='coolerdataset_predict', version='latest')\n",
    "filedst_10_models_input = filedst_10_models.as_named_input('forecast_10_models')\n",
    "\n",
    "training_experiment_name = \"connectedcooler-training-pipeline\"\n",
    "training_pipeline_run_id =\"<Training Pipeline Run ID from Notebook Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b69bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.automl.pipeline.steps import AutoMLPipelineBuilder\n",
    "\n",
    "partition_column_names = ['CoolerId', 'ItemSku']\n",
    "\n",
    "inference_steps = AutoMLPipelineBuilder.get_many_models_batch_inference_steps(experiment=experiment,\n",
    "                                                                              inference_data=filedst_10_models_input,\n",
    "                                                                              compute_target=compute,\n",
    "                                                                              node_count=2,\n",
    "                                                                              process_count_per_node=8,\n",
    "                                                                              run_invocation_timeout=300,\n",
    "                                                                              output_datastore=dstore,\n",
    "                                                                              train_experiment_name=training_experiment_name,\n",
    "                                                                              train_run_id=training_pipeline_run_id,\n",
    "                                                                              partition_column_names=partition_column_names,\n",
    "                                                                              time_column_name=\"PickListFulfilledTimestamp\",\n",
    "                                                                              target_column_name=\"ItemQuantity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0e836",
   "metadata": {},
   "source": [
    "### Submit the job to the inferencing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594811d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace = ws, steps=inference_steps)\n",
    "run = experiment.submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180e462",
   "metadata": {},
   "source": [
    "### Retrieve the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import sys \n",
    "from scripts.helper import get_forecasting_output\n",
    "\n",
    "forecasting_results_name = \"forecasting_results\"\n",
    "forecasting_output_name = \"many_models_inference_output\"\n",
    "\n",
    "forecast_file = get_forecasting_output(run, forecasting_results_name, forecasting_output_name)\n",
    "df = pd.read_csv(forecast_file, delimiter=\" \", header=None)\n",
    "df.columns = [\"PickListId\", \"PickListFulfilledTimestamp\", \"CoolerId\", \"ItemSku\",  \"ItemQuantity\",\"prediction\"]\n",
    "print(\"Prediction has \", df.shape[0], \" rows. Here the first 10 rows are being displayed.\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c586e",
   "metadata": {},
   "source": [
    "### From here, create the Inventory Projected table using the data from the forecast file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
